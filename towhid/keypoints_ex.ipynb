{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "# Initialize mediapipe solutions\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Define indices for specific facial features\n",
    "FACIAL_KEYPOINTS_INDICES = {\n",
    "    \"eyes\": list(range(33, 133)),  # Indices for eyes (approx)\n",
    "    \"eyebrows\": list(range(70, 80)) + list(range(100, 110)),  # Indices for eyebrows (approx)\n",
    "    \"lips\": list(range(287, 317)),  # Indices for lips (approx)\n",
    "    \"nose\": list(range(195, 230)),  # Indices for nose (approx)\n",
    "}\n",
    "\n",
    "# Collect all indices and ensure unique indices\n",
    "FACIAL_KEYPOINTS_INDICES = list(set(sum(FACIAL_KEYPOINTS_INDICES.values(), [])))\n",
    "\n",
    "def get_keypoints(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    hands = mp_hands.Hands(static_image_mode=True, max_num_hands=2, min_detection_confidence=0.5)\n",
    "    face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "    pose = mp_pose.Pose(static_image_mode=True, model_complexity=2, min_detection_confidence=0.5)\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Left and Right Hand keypoints\n",
    "    hand_results = hands.process(image_rgb)\n",
    "    left_hand_kp, right_hand_kp = np.zeros((21, 3)), np.zeros((21, 3))\n",
    "    if hand_results.multi_hand_landmarks:\n",
    "        for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "            if hand_landmarks:\n",
    "                hand_keypoints = np.array(\n",
    "                    [[lm.x * width, lm.y * height, lm.z] for lm in hand_landmarks.landmark])\n",
    "                if len(hand_keypoints) == 21:\n",
    "                    if hand_results.multi_handedness[0].classification[0].label == 'Left':\n",
    "                        left_hand_kp = hand_keypoints\n",
    "                    else:\n",
    "                        right_hand_kp = hand_keypoints\n",
    "    \n",
    "    # Face keypoints\n",
    "    face_results = face_mesh.process(image_rgb)\n",
    "    face_kp = np.zeros((70, 3))\n",
    "    if face_results.multi_face_landmarks:\n",
    "        for face_landmarks in face_results.multi_face_landmarks:\n",
    "            face_keypoints = np.array(\n",
    "                [[lm.x * width, lm.y * height, lm.z] for lm in face_landmarks.landmark])\n",
    "            selected_keypoints = face_keypoints[FACIAL_KEYPOINTS_INDICES]\n",
    "            if len(selected_keypoints) >= 70:  # Ensure at least 70 keypoints are available\n",
    "                face_kp[:70] = selected_keypoints[:70]  # Taking the first 70 keypoints from the selected ones\n",
    "    \n",
    "    # Pose keypoints\n",
    "    pose_results = pose.process(image_rgb)\n",
    "    pose_kp = np.zeros((23, 3))\n",
    "    if pose_results.pose_landmarks:\n",
    "        pose_keypoints = np.array(\n",
    "            [[lm.x * width, lm.y * height, lm.z] for lm in pose_results.pose_landmarks.landmark])\n",
    "        if len(pose_keypoints) == 33:  # Mediapipe pose has 33 points\n",
    "            pose_kp[:23] = pose_keypoints[:23]  # Taking only the first 23 keypoints\n",
    "\n",
    "    return left_hand_kp, right_hand_kp, face_kp, pose_kp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mdtow\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "image_path = r'F:\\SIGN_LANG\\edn\\EverybodyDanceNow\\towhid\\data\\train\\original_frames'\n",
    "image_name = 'frame020001'\n",
    "\n",
    "# Example function call, replace with actual image path\n",
    "left_hand_kp, right_hand_kp, face_kp, pose_kp = get_keypoints(image_path + '/' + image_name + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to YAML files successfully!\n"
     ]
    }
   ],
   "source": [
    "# # Prepare data for YAML format\n",
    "# data_lh = {\n",
    "#     'hand_left_0': {\n",
    "#         \"!!opencv-nd-matrix\": {\n",
    "#             'sizes': [1, 21, 3],\n",
    "#             'dt': 'f',\n",
    "#             'data': left_hand_kp.flatten().tolist()\n",
    "#         }\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# data_rh = {\n",
    "#     'hand_right_0': {\n",
    "#         'sizes': [1, 21, 3],\n",
    "#         'dt': 'f',\n",
    "#         'data': right_hand_kp.flatten().tolist()\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# data_face = {\n",
    "#     'face_0': {\n",
    "#         'sizes': [1, 70, 3],\n",
    "#         'dt': 'f',\n",
    "#         'data': face_kp.flatten().tolist()\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# data_pose = {\n",
    "#     \"pose_0\": {\n",
    "#         \"sizes\": [1, 23, 3],\n",
    "#         \"dt\": \"f\",\n",
    "#         \"data\": pose_kp.flatten().tolist()\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # Add the YAML version header\n",
    "# yaml_str = \"%YAML:1.0\\n\"\n",
    "\n",
    "# yaml_data_pose = yaml.dump(data_pose, default_flow_style=None)\n",
    "# yaml_str_pose = yaml_str + yaml_data_pose\n",
    "\n",
    "# yaml_data_face = yaml.dump(data_face, default_flow_style=None)\n",
    "# yaml_str_face = yaml_str + yaml_data_face\n",
    "\n",
    "# yaml_data_lh = yaml.dump(data_lh, default_flow_style=None)\n",
    "# yaml_str_lh = yaml_str + yaml_data_lh\n",
    "\n",
    "# yaml_data_rh = yaml.dump(data_rh, default_flow_style=None)\n",
    "# yaml_str_rh = yaml_str + yaml_data_rh\n",
    "\n",
    "yaml_str_lh = f\"\"\"%YAML:1.0\n",
    "face_0: !!opencv-nd-matrix\n",
    "  sizes: {[1, 21, 3]}\n",
    "  dt: f\n",
    "  data: {left_hand_kp.flatten().tolist()}\n",
    "\"\"\"\n",
    "\n",
    "yaml_str_rh = f\"\"\"%YAML:1.0\n",
    "face_0: !!opencv-nd-matrix\n",
    "  sizes: {[1, 21, 3]}\n",
    "  dt: f\n",
    "  data: {right_hand_kp.flatten().tolist()}\n",
    "\"\"\"\n",
    "\n",
    "yaml_str_face = f\"\"\"%YAML:1.0\n",
    "face_0: !!opencv-nd-matrix\n",
    "  sizes: {[1, 70, 3]}\n",
    "  dt: f\n",
    "  data: {face_kp.flatten().tolist()}\n",
    "\"\"\"\n",
    "\n",
    "yaml_str_pose = f\"\"\"%YAML:1.0\n",
    "face_0: !!opencv-nd-matrix\n",
    "  sizes: {[1, 23, 3]}\n",
    "  dt: f\n",
    "  data: {pose_kp.flatten().tolist()}\n",
    "\"\"\"\n",
    "\n",
    "keypoints_path = r'F:\\SIGN_LANG\\edn\\EverybodyDanceNow\\towhid\\data\\train\\keypoints'\n",
    "\n",
    "# Write data to YAML file\n",
    "with open(keypoints_path + '\\\\' + image_name + '_hand_left.yml', 'w') as file:\n",
    "    file.write(yaml_str_lh)\n",
    "\n",
    "with open(keypoints_path + '\\\\' + image_name + '_hand_right.yml', 'w') as file:\n",
    "    file.write(yaml_str_rh)\n",
    "\n",
    "with open(keypoints_path + '\\\\' + image_name + '_face.yml', 'w') as file:\n",
    "    file.write(yaml_str_face)\n",
    "\n",
    "with open(keypoints_path + '\\\\' + image_name + '_pose.yml', 'w') as file:\n",
    "    file.write(yaml_str_pose)\n",
    "\n",
    "print('Data written to YAML files successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAML file created successfully.\n"
     ]
    }
   ],
   "source": [
    "data_list = [1.02090930e+03, 1.51816254e+02, 6.56632066e-01]\n",
    "size_list = [1, 70, 3]\n",
    "\n",
    "# Construct the YAML content dynamically\n",
    "yaml_content = f\"\"\"%YAML:1.0\n",
    "face_0: !!opencv-nd-matrix\n",
    "  sizes: {size_list}\n",
    "  dt: f\n",
    "  data: {data_list}\n",
    "\"\"\"\n",
    "\n",
    "# Save to a .yml file\n",
    "with open('output.yml', 'w') as file:\n",
    "    file.write(yaml_content)\n",
    "\n",
    "print(\"YAML file created successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
